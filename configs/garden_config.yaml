# ============================================================================
# Garden Scene - Brown Plant Removal + Object Placement
# For use with the new pipeline architecture (run_pipeline.py)
# ============================================================================

project:
  name: "garden_brownplant_removal"
  scene: "garden"
  task: "removal_and_placement"
  description: "Remove brown plant from garden scene and place coffee cup"

# Paths - all outputs go to phase-based directories
paths:
  dataset_root: "datasets/360_v2/garden"
  output_root: "outputs/${project.name}"

# Output structure (phase-based)
output_structure:
  phase1_training:
    checkpoint: "ckpt_initial.pt"
    renders: "renders/"
    metrics: "metrics.json"
  phase2_segmentation:
    masks: "masks/"
    overlays: "overlays/"
    coverage: "coverage.csv"
  phase3_removal:
    holed_renders: "holed/renders/"
    inpainted: "inpainted/"
    optimized_checkpoint: "optimized/ckpt_final.pt"
  phase4_placement:
    final_checkpoint: "ckpt_with_object.pt"
    renders: "renders/"
    metrics: "metrics.json"

# Dataset settings
dataset:
  factor: 4                    # Downsample factor
  test_every: 8                # Test image frequency
  seed: 42                     # Random seed

# Phase 1: Training
training:
  iterations: 30000            # GS training iterations
  sh_degree: 3                 # Spherical harmonics degree
  eval_steps: [7000, 30000]    # Evaluation checkpoints
  save_steps: [7000, 30000]    # Save checkpoints

# Phase 2: Segmentation
segmentation:
  text_prompt: "brown plant"   # Object to segment
  box_threshold: 0.35          # GroundingDINO confidence
  text_threshold: 0.25         # Text matching threshold
  nms_threshold: 0.8           # Non-maximum suppression
  sam_model: "sam2_hiera_large"
  dino_selection: "largest"    # Use largest detected box
  sam_selection: null          # Use all SAM masks
  sam_thresh: 0.3
  
  # Spatial filtering
  reference_box: [0.36, 0.2, 0.64, 0.58]  # Focus region for brown plant
  reference_box_normalized: true
  reference_overlap_thresh: 0.7

# Phase 3: Removal
roi:
  threshold: 0.05              # ROI weight threshold
  min_views: 3                 # Min views for ROI inclusion

removal:
  method: "lama"               # Inpainting method
  optimization:
    iterations: 1000
    densification:
      start_iter: 100
      stop_iter: 800
      grad_thresh: 0.0002
      densify_every: 100
    learning_rates:
      means: 0.00016
      scales: 0.005
      quats: 0.001
      opacities: 0.05
      sh0: 0.0025
      shN: 0.0025

# Phase 4: Object Placement
placement:
  object_gaussians: "GaussianDreamerResults/coffee_cup_pro.ply"
  scale: 0.05                  # Object scale multiplier
  xyz_offset: [-0.17, -0.05, 0.0]  # XYZ offset from ROI center
  rotation_degrees: 0.0        # Rotation around Z-axis
  
  # Visualization
  num_eval_views: 20
  metrics: ["clip", "lpips", "ssim", "psnr"]
  clip_model: "ViT-B/32"

# Hardware
hardware:
  device: "cuda"
  num_workers: 4
  mixed_precision: true

# Logging
logging:
  level: "INFO"
  save_renders: true
  save_frequency: 100
